<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
<script>
    var _hmt = _hmt || [];
    (function() {
	      var hm = document.createElement("script");
	      hm.src = "//hm.baidu.com/hm.js?98cc862d4b99529da444b0b16203e7e7";
		  var s = document.getElementsByTagName("script")[0]; 
		  s.parentNode.insertBefore(hm, s);
    })();
</script>



  
  <title>如何通过 python 实现一个`正经` tumblr 爬虫 | facert 的杂货店</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="直接入正题，写一个 python 爬虫，最重要的其实是找到入口，从哪里开始爬，以 tumblr 为例，只要能够获取到用户列表，通过每个用户的主页就能拿到每个用户发的或者转发的视频，原作者的名字也可以拿到。">
<meta property="og:type" content="article">
<meta property="og:title" content="如何通过 python 实现一个`正经` tumblr 爬虫">
<meta property="og:url" content="https://facert.github.io/2016/11/21/如何通过-python-实现一个-正经-tumblr-爬虫/index.html">
<meta property="og:site_name" content="facert 的杂货店">
<meta property="og:description" content="直接入正题，写一个 python 爬虫，最重要的其实是找到入口，从哪里开始爬，以 tumblr 为例，只要能够获取到用户列表，通过每个用户的主页就能拿到每个用户发的或者转发的视频，原作者的名字也可以拿到。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2016-11-26T08:50:34.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="如何通过 python 实现一个`正经` tumblr 爬虫">
<meta name="twitter:description" content="直接入正题，写一个 python 爬虫，最重要的其实是找到入口，从哪里开始爬，以 tumblr 为例，只要能够获取到用户列表，通过每个用户的主页就能拿到每个用户发的或者转发的视频，原作者的名字也可以拿到。">
  
    <link rel="alternate" href="/atom.xml" title="facert 的杂货店" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">facert 的杂货店</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://facert.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-如何通过-python-实现一个-正经-tumblr-爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/21/如何通过-python-实现一个-正经-tumblr-爬虫/" class="article-date">
  <time datetime="2016-11-21T05:56:53.000Z" itemprop="datePublished">2016-11-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      如何通过 python 实现一个`正经` tumblr 爬虫
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>直接入正题，写一个 python 爬虫，最重要的其实是找到入口，从哪里开始爬，以 tumblr 为例，只要能够获取到用户列表，通过每个用户的主页就能拿到每个用户发的或者转发的视频，原作者的名字也可以拿到。<br><a id="more"></a><br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self, url)</span>:</span></span><br><span class="line">    <span class="comment"># 用 requests 库获取 url 的网页内容</span></span><br><span class="line">    res = requests.get(url)</span><br><span class="line">    <span class="comment"># 用 bs4 解析 html</span></span><br><span class="line">    soup = BeautifulSoup(res.text)  </span><br><span class="line">    <span class="comment"># 获取 iframe 标签列表</span></span><br><span class="line">    iframes = soup.find_all(<span class="string">'iframe'</span>)</span><br><span class="line">    tmp_source = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> iframes:</span><br><span class="line">        <span class="comment"># 获取视频地址</span></span><br><span class="line">        source = i.get(<span class="string">'src'</span>, <span class="string">''</span>).strip()</span><br><span class="line">        <span class="comment"># 过滤内容</span></span><br><span class="line">        <span class="keyword">if</span> source <span class="keyword">and</span> source.find(<span class="string">'https://www.tumblr.com/video'</span>) != <span class="number">-1</span> <span class="keyword">and</span> source <span class="keyword">not</span> <span class="keyword">in</span> self.total_url:</span><br><span class="line">            tmp_source.append(source)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">u'新增链接:'</span> + source</span><br><span class="line"></span><br><span class="line">    tmp_user = []</span><br><span class="line">    <span class="comment"># 获取用户列表</span></span><br><span class="line">    new_users = soup.find_all(class_=<span class="string">'reblog-link'</span>)</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> new_users:</span><br><span class="line">        username = user.text.strip()</span><br><span class="line">        <span class="comment"># 过滤用户</span></span><br><span class="line">        <span class="keyword">if</span> username <span class="keyword">and</span> username <span class="keyword">not</span> <span class="keyword">in</span> self.total_user:</span><br><span class="line">            <span class="comment"># 将用户放入待爬取队列</span></span><br><span class="line">            self.user_queue.put(username)</span><br><span class="line">            <span class="comment"># 加入总用户列表中</span></span><br><span class="line">            self.total_user.append(username)</span><br><span class="line">            tmp_user.append(username)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">u'新增用户:'</span> + username</span><br></pre></td></tr></table></figure>
<p>为了提高爬虫的性能，可以采用多线程的方式，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Tumblr</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 为了能处理多线程 ctr+c 的信号问题，具体见完整代码</span></span><br><span class="line">        <span class="keyword">global</span> is_exit</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_exit:</span><br><span class="line">            user = self.user_queue.get()</span><br><span class="line">            url = <span class="string">'http://%s.tumblr.com/'</span> % user</span><br><span class="line">            self.download(url)</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 线程数</span></span><br><span class="line">    NUM_WORKERS = <span class="number">10</span></span><br><span class="line">    <span class="comment"># 待爬取队列</span></span><br><span class="line">    queue = Queue.Queue()</span><br><span class="line">    <span class="comment"># 开始的时候将一个热门博主的 username 加入到待爬取队列</span></span><br><span class="line">    queue.put(<span class="string">'username'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(NUM_WORKERS):</span><br><span class="line">        <span class="comment"># 实例化线程对象</span></span><br><span class="line">        tumblr = Tumblr(queue)</span><br><span class="line">        <span class="comment"># 设置线程为守护线程</span></span><br><span class="line">        tumblr.setDaemon(<span class="keyword">True</span>)</span><br><span class="line">        tumblr.start()</span><br></pre></td></tr></table></figure>
<p>最后将用户和视频资源写入到文件中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于多线程写文件会出现线程安全问题，所以加了个线程锁</span></span><br><span class="line">mutex.acquire()</span><br><span class="line"><span class="keyword">if</span> tmp_user:</span><br><span class="line">    self.f_user.write(<span class="string">'\n'</span>.join(tmp_user)+<span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">if</span> tmp_source:</span><br><span class="line">    self.f_source.write(<span class="string">'\n'</span>.join(tmp_source)+<span class="string">'\n'</span>)</span><br><span class="line"><span class="comment"># 释放锁</span></span><br><span class="line">mutex.release()</span><br></pre></td></tr></table></figure>
<p>这样一个多线程 python 爬虫就基本完成了，完整代码见 <a href="https://github.com/facert/tumblr_spider" target="_blank" rel="noopener">github</a></p>
<p>最后声明这是一个正经的爬虫（严肃脸），爬取的资源跟你第一个填入的 username 有很大关系，老司机怎么开车我不管 ╭(╯^╰)╮</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://facert.github.io/2016/11/21/如何通过-python-实现一个-正经-tumblr-爬虫/" data-id="ck9fd0vkl0012bls6j7x5roek" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/11/24/过滤豆瓣租房小组中介贴之 python 实现余弦相似度（一）/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          过滤豆瓣租房小组中介贴之 python 实现余弦相似度（一）
        
      </div>
    </a>
  
  
    <a href="/2016/11/19/微信找房机器人的实现/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">微信找房机器人</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DIY/">DIY</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IPFS/">IPFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/django源码/">django源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ghost/">ghost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ipfs/">ipfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-入门/">python 入门</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web/">web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web-django/">web, django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/web开发/">web开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/代理/">代理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/以太坊/">以太坊</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/前端/">前端</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/思考/">思考</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/智能合约/">智能合约</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算机系统/">计算机系统</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/IPFS/" style="font-size: 10px;">IPFS</a> <a href="/tags/algorithm/" style="font-size: 15px;">algorithm</a> <a href="/tags/django源码/" style="font-size: 10px;">django源码</a> <a href="/tags/ghost/" style="font-size: 10px;">ghost</a> <a href="/tags/ipfs/" style="font-size: 20px;">ipfs</a> <a href="/tags/python-入门/" style="font-size: 20px;">python 入门</a> <a href="/tags/web/" style="font-size: 15px;">web</a> <a href="/tags/web-django/" style="font-size: 10px;">web, django</a> <a href="/tags/web开发/" style="font-size: 10px;">web开发</a> <a href="/tags/代理/" style="font-size: 15px;">代理</a> <a href="/tags/以太坊/" style="font-size: 10px;">以太坊</a> <a href="/tags/前端/" style="font-size: 10px;">前端</a> <a href="/tags/思考/" style="font-size: 10px;">思考</a> <a href="/tags/数据结构/" style="font-size: 12.5px;">数据结构</a> <a href="/tags/智能合约/" style="font-size: 17.5px;">智能合约</a> <a href="/tags/计算机系统/" style="font-size: 10px;">计算机系统</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/04/25/深入理解-IPFS-消费-订阅系统/">深入理解 IPFS - 消费/订阅系统</a>
          </li>
        
          <li>
            <a href="/2020/04/25/深入理解-IPFS-分布式代理/">深入理解 IPFS - 分布式代理</a>
          </li>
        
          <li>
            <a href="/2020/04/25/深入理解-IPFS-DHT-网络（1）/">深入理解 IPFS - DHT 网络（1）</a>
          </li>
        
          <li>
            <a href="/2020/04/25/深入理解-IPFS-分层架构总览/">深入理解 IPFS - 分层架构总览</a>
          </li>
        
          <li>
            <a href="/2018/12/22/基于-IPFS-的去中心化短链接服务/">基于 IPFS 的去中心化短链接服务</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 facert<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>