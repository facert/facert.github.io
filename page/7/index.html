<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 程序化思维</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://facert.github.io/atom.xml" title="程序化思维"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/facert" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><ul class="home post-list"><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/02/04/过滤豆瓣租房小组中介贴之 python 实现 TF-IDF 算法（二）/" class="post-title-link">过滤豆瓣租房小组中介贴之 python 实现 TF-IDF 算法（二）</a></h2><div class="post-info">Feb 4, 2017</div><div class="post-content"><p>前段时间写过一篇 <a href="https://facert.github.io/2016/11/24/%E8%BF%87%E6%BB%A4%E8%B1%86%E7%93%A3%E7%A7%9F%E6%88%BF%E5%B0%8F%E7%BB%84%E4%B8%AD%E4%BB%8B%E8%B4%B4%E4%B9%8B%20python%20%E5%AE%9E%E7%8E%B0%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89/">过滤豆瓣租房小组中介贴之 python 实现余弦相似度（一）</a>, 这里面使用 <code>jieba</code> 将文档分词，然后计算对分词的结果向量化计算相似度。比如 <code>我的房子在方庄地铁附近的芳城园一区</code> 会被分词为 <code>方庄 芳城园 一区 地铁 房子 附近</code>，我们发现少了 <code>我 的 在</code> 这些词，在自然语言处理的过程中，称这些词为停用词，简单的说就是这些词对于分词结果没有多少帮助，所以需要直接过滤掉。因为我们直接调用 <code>jieba.analyse</code> 方法，所以停用词被直接过滤了，如果只是调用 <code>jieba.cut</code>，会将返回包含停用词的结果。<br></div><a href="/2017/02/04/过滤豆瓣租房小组中介贴之 python 实现 TF-IDF 算法（二）/" class="read-more">...more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/02/04/过滤豆瓣租房小组中介贴之 python 实现 布隆过滤器（三）/" class="post-title-link">过滤豆瓣租房小组中介贴之 python 实现 布隆过滤器（三）</a></h2><div class="post-info">Feb 4, 2017</div><div class="post-content"><p>其实这篇文章跟过滤中介贴没什么关系，只是在爬豆瓣小组的时候遇到的一点思考，我们知道，其实爬虫就是循环的爬取网站的 url，但是怎么判断爬取的 url 是否重复呢，最简单的，维护一个列表，每次循环查找，很明显效率很低。进阶的，采用哈希表，每次查询都是 O(1), 看上去不错。不过如果一旦 url 大到一定程度时，单台机器的内存肯定吃不消，这个时候分布式方案就呼之欲出，变得越来越复杂。那么能不能在牺牲一点点精确性的前提下，有简单的方案呢，答案是肯定的。这就是 布隆过滤器。<br></div><a href="/2017/02/04/过滤豆瓣租房小组中介贴之 python 实现 布隆过滤器（三）/" class="read-more">...more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2016/12/21/ghost-博客中文搜索插件/" class="post-title-link">ghost 博客中文搜索插件</a></h2><div class="post-info">Dec 21, 2016</div><div class="post-content"><p>在用 ghost 博客的时候，发现一直没有合适的搜索插件，主要是官方没提供相应的 search api, <a href="https://github.com/dreampiggy/ghostHunter" target="_blank" rel="noopener">ghostHunter</a> 采用 api 获取所有文章的方式，然后用 lunir 做全文搜索。但是 lunir 本身不支持中文分词，虽然有小伙伴提供了中文分词的方案，但是为了一个简单的搜索加了好大一堆库，感觉还是不怎么经济。</p>
<p>所以鉴于此，根据 ghsotHunter 改了个简单的插件，为了效率，api 获取的时候只取 title, 所以只支持简单的 title 匹配搜索, 代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> searchResult = [];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>; i &lt; <span class="keyword">this</span>.blogData.length; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span>(value &amp;&amp; <span class="keyword">this</span>.blogData[i].title.toLowerCase().search(value.toLowerCase()) != <span class="number">-1</span>)&#123;</span><br><span class="line">    searchResult.push(<span class="keyword">this</span>.blogData[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><a href="/2016/12/21/ghost-博客中文搜索插件/" class="read-more">...more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2016/12/15/2016-关于技术和人生的一些碎碎念/" class="post-title-link">2016 关于技术和人生的一些碎碎念</a></h2><div class="post-info">Dec 15, 2016</div><div class="post-content"></div><a href="/2016/12/15/2016-关于技术和人生的一些碎碎念/" class="read-more">...more</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2016/12/09/django-防御-csrf-源码分析/" class="post-title-link">django 安全之防御 csrf</a></h2><div class="post-info">Dec 9, 2016</div><div class="post-content"><h4 id="本文主要通过分析-django-源码-介绍-django-在-csrf-跨站请求伪造-的防御措施，-默认大家对-csrf-有一定的了解"><a href="#本文主要通过分析-django-源码-介绍-django-在-csrf-跨站请求伪造-的防御措施，-默认大家对-csrf-有一定的了解" class="headerlink" title="本文主要通过分析 django 源码 介绍 django 在 csrf (跨站请求伪造) 的防御措施， 默认大家对 csrf 有一定的了解"></a>本文主要通过分析 django 源码 介绍 django 在 csrf (跨站请求伪造) 的防御措施， 默认大家对 csrf 有一定的了解</h4></div><a href="/2016/12/09/django-防御-csrf-源码分析/" class="read-more">...more</a></article></li></ul></main><footer><div class="paginator"><a href="/page/6/" class="prev">PREV</a><a href="/page/8/" class="next">NEXT</a></div><div class="copyright"><p>© 2021 <a href="https://facert.github.io">facert</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>